from seedemu.core import Emulator, Compiler, Registry, ScopedRegistry, Node, AutonomousSystem
from seedemu.core.enums import NetworkType
from os import mkdir, chdir
import os
import json
from hashlib import md5

class GhostPrinter(Compiler):
    """!
    @brief Get all graphable object and graph them.

    """

    def getName(self) -> str:
        return 'GhostPrinter'
        
    def _contextToPrefix(self, scope: str, type: str) -> str:
        """!
        @brief Convert context to prefix.

        @param scope scope.
        @param type type.

        @returns prefix string.
        """
        return '{}_{}_'.format(type, scope)
        
    def _addFile(self, path: str, content: str) -> str:
        """!
        @brief Stage file to local folder and return Dockerfile command.

        @param path path to file. (in container)
        @param content content of the file.

        @returns COPY expression for dockerfile.
        """

        staged_path = md5(path.encode('utf-8')).hexdigest()
        print(content, file=open(staged_path, 'w'))
        return 'COPY {} {}\n'.format(staged_path, path)
        
    def __printJson(self, node: Node) -> str:
        """!
        @brief print out all information about a single node in the JSON format. 
        Will create folder for node and the Json.

        @param node node to print.

        @returns node information in Json format string.
        """
        info = {}
        
        info["Name"] = node.getName()
        
        (scope, type, _) = node.getRegistryInfo()
        prefix = '{}_{}_'.format(type, scope)
        real_nodename = '{}{}'.format(prefix, node.getName())
        info["NodeId"] = real_nodename
        
        info["Role"] = '{}'.format(node.getRole())

        info["Ghost_Node"] = '{}'.format(node.isGhostnode())
        
        info["Autonomous_Systems"] = node.getAsn()
        
        info["Interfaces"] = []
        for interface in node.getInterfaces():
            info["Interfaces"].append(json.loads(interface.printJson()))
        
        info["Files"] = []
        for file in node.getFiles():
            info["Files"].append(json.loads(file.printJson()))
        
        info["Sofewares"] = list(node.getSoftware())
        
        info["Build_Commands"] = node.getBuildCommands()
        
        info["Start_Commands"] = node.getStartCommands()

        info["Post_Config_Commands"] = node.getPostConfigCommands()
        
        json_str = json.dumps(info, indent=4)
        return json_str
        
    def _compileGhostNode_backup(self, node: Node, emulator: Emulator) -> str:
        """!
        @brief Compile a single ghost node. Will create folder for node and the
        dockerfile. but NOT create docker-compose service string

        @param node node to compile. 
                ****emulator: Emulator, this can be removed if the construct 
                customized etchosts can be done in etc-host render function****

        @returns docker-compose service string. ***** need to be parties.conf string
        """
        ########################################################
        ## should generated by fate services because it is not general 
        DockerCompilerFileTemplates: Dict[str, str] = {}

        DockerCompilerFileTemplates['egg'] = """\
        ARG DEBIAN_FRONTEND=noninteractive
        """
        
        ########################################################
        (scope, type, _) = node.getRegistryInfo()
        prefix = self._contextToPrefix(scope, type)
        real_nodename = '{}{}'.format(prefix, node.getName())
        
        mkdir(real_nodename)
        chdir(real_nodename)
        
        # better way is move the etc-hosts generating part to EtcHosts Layers render()
        # compile function only take care of creating files and folders
        layers_name = [layer.getName() for layer in emulator.getLayers()]
        if 'EtcHosts' in layers_name:
            etc_hosts = emulator.getLayer('EtcHosts')
            hosts_file_content = []
            reg = emulator.getRegistry()
            workdir=os.getcwd()
            with open(workdir+'/../../pre_party_list.json', 'r') as arch_json:
                arch_data = json.load(arch_json)
            for party in arch_data.values():
                # find the party the nodes belong to
                if real_nodename in party.values():
                    # construct the etc-hosts file
                    # TODO
                    # not correct! because these are other nodes which are not Fate component, should be include in ect/hosts
                    for component, nodeid in party.items():
                        for ((scope, type, name), tmp_node) in reg.getAll().items():
                            if type in ['hnode', 'snode', 'rnode', 'rs']:
                                prefix = self._contextToPrefix(scope, type)
                                nodename = '{}{}'.format(prefix, tmp_node.getName())
                                # if it is the node we are looking for
                                # it will not be necessary if using fate service layer, stores Node obj directly 
                                if nodeid == nodename:
                                    #addresses = etc_hosts.__getAllIpAddress(tmp_node)
                                    # does not have public function, maybe add later
                                    addresses = []
                                    for iface in tmp_node.getInterfaces():
                                        address = iface.getAddress()
                                        if iface.getNet().getType() == NetworkType.Bridge:
                                            pass
                                        if iface.getNet().getType() == NetworkType.InternetExchange:
                                            pass
                                        else:
                                            addresses.append(address)
                                    ###################################### reason1: move it to ecthost render
                                    for address in addresses:
                                        hosts_file_content.append(f"{address} {' '.join(tmp_node.getHostNames()+[component])}")
                    sorted_hosts_file_content = sorted(hosts_file_content, \
                    key=lambda x: tuple(map(int, x.split()[0].split('.'))))            
                    break
            node.setFile("/tmp/etc-hosts", '\n'.join(sorted_hosts_file_content))
        
        with open(workdir+'/../../node_component.json', 'r') as node_component_json:
            node_component = json.load(node_component_json)
        #dockfile = DockerCompilerFileTemplates[node_component[real_nodename]]
        for file in node.getFiles():
            (path, content) = file.get()
            #dockerfile += self._addFile(path, content)
            self._addFile(path, content)
        
        chdir('..')
            
        #######################################################
        
    def _compileGhostNode(self, node: Node) -> str:
        """!
        @brief Compile a single ghost node. Will create folder for node and the
        dockerfile. but NOT create docker-compose service string

        @param node node to compile. 

        @returns None
        """
        (scope, type, _) = node.getRegistryInfo()
        prefix = self._contextToPrefix(scope, type)
        real_nodename = '{}{}'.format(prefix, node.getName())
        
        mkdir(real_nodename)
        chdir(real_nodename)
        
        # dockerfile header can be pre-process by services for different components
        dockerfile_content = ""
        
        for cmd in node.getBuildCommands(): dockerfile_content += 'RUN {}\n'.format(cmd)
        
        start_commands = ''
        
        for (cmd, fork) in node.getStartCommands():
            start_commands += '{}{}\n'.format(cmd, ' &' if fork else '')

        for (cmd, fork) in node.getPostConfigCommands():
            start_commands += '{}{}\n'.format(cmd, ' &' if fork else '')
        
        dockerfile_content += self._addFile('/start.sh', start_commands)
        
        for file in node.getFiles():
            (path, content) = file.get()
            if path != "Dockerfile":
                dockerfile_content += self._addFile(path, content)
        
        for (cpath, hpath) in node.getImportedFiles().items():
            dockerfile_content += self._importFile(cpath, hpath)
            
        dockerfile_content += 'ENTRYPOINT ["sh", "/start.sh"]\n'
        node.appendFile('Dockerfile', dockerfile_content)
        (_, dockerfile) = node.getFile('Dockerfile').get()
        print(dockerfile, file=open('Dockerfile', 'w'))
        
        chdir('..')

    def _doCompile(self, emulator: Emulator):
        registry = emulator.getRegistry()
        self._log('print ghost node information ...')
        
        node_info = []
        ASN_set = set()
        for ((scope, type, name), obj) in registry.getAll().items():
            if type == 'hnode' and obj.isGhostnode():
                self._log('compiling ghost node {} for as{}...'.format(scope, name))
                ASN_set.add(obj.getAsn())
                ghost_node_info = json.loads(self.__printJson(obj))
                node_info.append(ghost_node_info)
        
        json_str = json.dumps(node_info, indent=4)  
        self._log('creating ghost_nodes.json...')
        print(json_str, file=open('GhostNodes.json', 'w'))
        
        AS_info = []
        base = emulator.getLayer("Base")
        for asn in ASN_set:
            AS = base.getAutonomousSystem(asn)
            #TODO printJsonBrief to printJson
            as_info = json.loads(AS.printJsonBrief())
            AS_info.append(as_info)
            
        as_json_str = json.dumps(AS_info, indent=4)  
        self._log('creating Autonomous_Systems.json...')
        print(as_json_str, file=open('AutonomousSystems.json', 'w'))
        
        # output the complete etc-hosts file for method 1
        '''
        layers_name = [layer.getName() for layer in emulator.getLayers()]
        if 'EtcHosts' in layers_name:
            etc_hosts = emulator.getLayer('EtcHosts')
            hosts_file_content = []
            for ((scope, type, name), node) in registry.getAll().items():
                if type in ['hnode', 'snode', 'rnode', 'rs']:
                    #addresses = etc_hosts.__getAllIpAddress(node)
                    # does not have public function, maybe add later
                    addresses = []
                    for iface in node.getInterfaces():
                        address = iface.getAddress()
                        if iface.getNet().getType() == NetworkType.Bridge:
                            pass
                        if iface.getNet().getType() == NetworkType.InternetExchange:
                            pass
                        else:
                            addresses.append(address)
		    ######################################
                    for address in addresses:
                        hosts_file_content.append(f"{address} {' '.join(node.getHostNames())}")
            sorted_hosts_file_content = sorted(hosts_file_content, key=lambda x: tuple(map(int, x.split()[0].split('.'))))
            print('\n'.join(sorted_hosts_file_content), file=open('etc-hosts', 'w'))
        '''
        # TODO should output parties.conf
        for ((scope, type, name), obj) in registry.getAll().items():
            if type == 'hnode' and obj.isGhostnode():
                self._compileGhostNode(obj)
            
